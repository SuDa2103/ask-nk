{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI's Whisper\n",
    "\n",
    "Whisper is an **A**utomatic **S**peech **R**ecognition (ASR) model from OpenAI. We use it to extract highly accurate text from YouTube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1bazlzfa\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1bazlzfa\n",
      "  Resolved https://github.com/openai/whisper.git to commit 9e653bd0ea0f1e9493cb4939733e9de249493cfb\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.21.6)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (1.12.1.post200)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.64.0)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (8.14.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (4.21.3)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /opt/conda/lib/python3.7/site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (4.11.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.8.17)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (0.9.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
      "Hit:1 http://packages.cloud.google.com/apt cloud-sdk-buster InRelease\n",
      "Hit:2 http://packages.cloud.google.com/apt google-cloud-packages-archive-keyring-buster InRelease\n",
      "Get:3 https://packages.cloud.google.com/apt google-fast-socket InRelease [5405 B]\n",
      "Get:4 http://packages.cloud.google.com/apt gcsfuse-buster InRelease [5391 B]   \u001b[0m\u001b[33m\n",
      "Hit:5 http://packages.cloud.google.com/apt google-compute-engine-buster-stable InRelease\n",
      "Hit:6 https://packages.cloud.google.com/apt kubernetes-xenial InRelease        \u001b[0m\u001b[33m\n",
      "Get:7 https://download.docker.com/linux/debian buster InRelease [54.0 kB]      \u001b[0m\n",
      "Hit:8 http://deb.debian.org/debian buster InRelease                            \u001b[0m\n",
      "Hit:9 http://security.debian.org/debian-security buster/updates InRelease      \u001b[0m\n",
      "Hit:10 https://nvidia.github.io/libnvidia-container/stable/debian10/amd64  InRelease[33m\n",
      "Get:11 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]  \u001b[0m   \n",
      "Get:12 https://nvidia.github.io/nvidia-container-runtime/stable/debian10/amd64  InRelease [1481 B]\n",
      "Get:13 https://nvidia.github.io/nvidia-docker/debian10/amd64  InRelease [1474 B][0m\u001b[33m\n",
      "Get:14 http://deb.debian.org/debian buster-backports InRelease [51.4 kB]       \u001b[0m\u001b[33m\n",
      "Hit:15 https://packagecloud.io/github/git-lfs/debian buster InRelease          \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Fetched 176 kB in 1s (123 kB/s)33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "8 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.1.9-0+deb10u1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!sudo apt update -y && sudo apt install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model = whisper.load_model(\"large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration jamescalam--channel-metadata-872f7e2f9a088c57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/jamescalam--channel-metadata to /home/jupyter/.cache/huggingface/datasets/jamescalam___json/jamescalam--channel-metadata-872f7e2f9a088c57/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/362k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 362k/362k [00:00<00:00, 3.29MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 950.01it/s]\n",
      "                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/jupyter/.cache/huggingface/datasets/jamescalam___json/jamescalam--channel-metadata-872f7e2f9a088c57/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Video ID', 'Channel ID', 'Title', 'Time Created', 'Time Published', 'Duration', 'Description', 'Category', 'Like Count', 'Dislike Count'],\n",
       "    num_rows: 222\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "videos_meta = load_dataset(\n",
    "    \"jamescalam/channel-metadata\",\n",
    "    split=\"train\"\n",
    ")\n",
    "videos_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create videos metadata dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dict = {}\n",
    "\n",
    "for row in videos_meta:\n",
    "    # create entry in dict\n",
    "    videos_dict[row['Video ID']] = {\n",
    "        'title': row['Title'],\n",
    "        'published': row['Time Published'],\n",
    "        'url': f\"https://youtu.be/{row['Video ID']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "['mp3/35Pdoyi6ZoQ.mp3', 'mp3/B7wmo_NImgM.mp3', 'mp3/x1lAcT3xl5M.mp3', 'mp3/r-zQQ16wTCA.mp3', 'mp3/DFtP1THE8fE.mp3']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# get list of MP3 audio files\n",
    "paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n",
    "print(len(paths))\n",
    "print(paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35Pdoyi6ZoQ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the IDs like so\n",
    "paths[0].split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/108 [00:00<?, ?it/s]2022-10-13 10:56:36.068291: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "100%|██████████| 108/108 [7:10:39<00:00, 239.26s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27214"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# set window (length of text chunk) and stride\n",
    "window = 1\n",
    "stride = 1  # smaller stride creates overlap\n",
    "\n",
    "data = []\n",
    "\n",
    "results = []\n",
    "with open(\"transcription.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    for i, path in enumerate(tqdm(paths)):\n",
    "        _id = path.split('/')[-1][:-4]\n",
    "        # transcribe to get speech-to-text data\n",
    "        result = model.transcribe(path)\n",
    "        segments = result['segments']\n",
    "        # get the video metadata...\n",
    "        video_meta = videos_dict[_id]\n",
    "        for j in range(0, len(segments), stride):\n",
    "            j_end = min(j+window, len(segments)-1)\n",
    "            text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n",
    "            start = segments[j]['start']\n",
    "            end = segments[j_end]['end']\n",
    "            row_id = f\"{_id}-t{segments[j]['start']}\"\n",
    "            meta = {\n",
    "                **video_meta,\n",
    "                **{\n",
    "                    \"id\": row_id,\n",
    "                    \"text\": text.strip(),\n",
    "                    \"start\": start,\n",
    "                    \"end\": end\n",
    "                }\n",
    "            }\n",
    "            data.append(meta)\n",
    "            json.dump(meta, fp)\n",
    "            fp.write('\\n')\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Append more to dataset without overwriting/redoing\n",
    "\n",
    "First check what we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "existing_ids = []\n",
    "\n",
    "with open(\"transcription.jsonl\", 'r', encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        obj = json.loads(line)\n",
    "        existing_ids.append(obj['url'].split('/')[-1])\n",
    "\n",
    "existing_ids = set(existing_ids)\n",
    "len(existing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gVAJ_l_S7uQ', '1gN1snKBLP0', 'YvVQgvAz9dY', '3Wqh4iUupbM', 'jjQetJtQDS4']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(existing_ids)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get paths to videos not already in `existing_ids`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "['mp3/35Pdoyi6ZoQ.mp3', 'mp3/B7wmo_NImgM.mp3', 'mp3/x1lAcT3xl5M.mp3', 'mp3/r-zQQ16wTCA.mp3', 'mp3/DFtP1THE8fE.mp3']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = [str(x) for x in Path('./mp3').glob('*.mp3')]\n",
    "print(len(paths))\n",
    "print(paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "paths = [x for x in paths if x.split('/')[-1][:-4] not in existing_ids]\n",
    "print(len(paths))\n",
    "print(paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# set window (length of text chunk) and stride\n",
    "window = 1\n",
    "stride = 1  # smaller stride creates overlap\n",
    "\n",
    "results = []\n",
    "with open(\"transcription.jsonl\", \"a\", encoding=\"utf-8\") as fp:\n",
    "    for i, path in enumerate(tqdm(paths)):\n",
    "        _id = path.split('/')[-1][:-4]\n",
    "        # transcribe to get speech-to-text data\n",
    "        result = model.transcribe(path)\n",
    "        segments = result['segments']\n",
    "        # get the video metadata...\n",
    "        video_meta = videos_dict[_id]\n",
    "        for j in range(0, len(segments), stride):\n",
    "            j_end = min(j+window, len(segments)-1)\n",
    "            text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n",
    "            start = segments[j]['start']\n",
    "            end = segments[j_end]['end']\n",
    "            _id = f\"{_id}-t{segments[j]['start']}\"\n",
    "            meta = {\n",
    "                **video_meta,\n",
    "                **{\n",
    "                    \"id\": _id,\n",
    "                    \"text\": text.strip(),\n",
    "                    \"start\": start,\n",
    "                    \"end\": end\n",
    "                }\n",
    "            }\n",
    "            json.dump(meta, fp)\n",
    "            fp.write('\\n')\n",
    "\n",
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
